{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/24 18:09:21 WARN Utils: Your hostname, admins-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 172.30.1.45 instead (on interface en0)\n",
      "24/08/24 18:09:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/24 18:09:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/24 18:09:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/adoptopenjdk-16.jdk/Contents/Home'\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pyspark.pandas as ps\n",
    "ps.set_option('compute.ops_on_diff_frames', True)\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('spark-job') \\\n",
    "    .config('spark.executor.memory', '4gb') \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE UPDATED\n",
    "POST_FP = \"../EDA/gu/data/아이오닉 누수/clien_posts.csv\" # from S3\n",
    "COMMENT_FP = \"../EDA/gu/data/아이오닉 누수/clien_comments.csv\" # from S3\n",
    "MODEL_FP = \"../model_result.csv\" # from RedShift\n",
    "OUTPUT_FP = \"output/transform_result\" # to RedShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hot_criteria(row, model_df) -> np.float64:\n",
    "    condition = ((model_df['post_type']==1) \\\n",
    "        & (model_df['relative_time']==row.relatvie_time) \\\n",
    "        & (model_df['cumulative_num']==row.comments))\n",
    "    hot_pdf_value = model_df[condition].pdf.values[0]\n",
    "    # print(\"find_hot_criteria\", type(hot_pdf_value))\n",
    "    return hot_pdf_value\n",
    "\n",
    "\n",
    "def find_cold_criteria(row, model_df) -> np.float64:\n",
    "    condition = ((model_df['post_type']==0) \\\n",
    "        & (model_df['relative_time']==row.relatvie_time) \\\n",
    "        & (model_df['cumulative_num']==row.comments))\n",
    "    cold_pdf_value = model_df[condition].pdf.values[0]\n",
    "    # print(\"find_cold_criteria\", type(cold_pdf_value))\n",
    "    return cold_pdf_value\n",
    "\n",
    "\n",
    "def predict_post_type(post_df, model_df) -> ps.DataFrame:  \n",
    "    per_post_hot_probability = post_df.apply(lambda x: find_hot_criteria(x, model_df), axis=1)\n",
    "    per_post_cold_probability = post_df.apply(lambda x: find_cold_criteria(x, model_df), axis=1)\n",
    "    post_df['impact'] = np.log(per_post_hot_probability/per_post_cold_probability).round(2)\n",
    "    post_df['post_type'] = 0\n",
    "    post_df.loc[post_df['impact'] > 0, 'post_type'] = 1    \n",
    "    return post_df\n",
    "\n",
    "\n",
    "def parse_date(date_str):\n",
    "    return ps.to_datetime(date_str, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "post_df = spark.read.option(\"header\", True).option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"multiline\", \"true\").option(\"sep\", \",\").csv(POST_FP, sep=',',).pandas_api()\n",
    "comment_df = spark.read.option(\"header\", True).option(\"quote\", \"\\\"\").option(\"multiline\", \"true\").csv(COMMENT_FP, sep=',').pandas_api() \n",
    "model_df = spark.read.option(\"header\", True).csv(MODEL_FP, sep=',').pandas_api()\n",
    "\n",
    "collected_at = ps.to_datetime('2023-10-31 00:00:52').replace(second=0, microsecond=0) # from S3 (crawling)\n",
    "if collected_at.minute >= 30:\n",
    "    collected_at = collected_at.replace(minute=30)\n",
    "else:\n",
    "    collected_at = collected_at.replace(minute=00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.to_datetime(\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  return pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "post_df['created_at'] = post_df['created_at'].apply(parse_date)\n",
    "comment_df.columns = ['cmt_author', 'cmt_content', 'post_id', 'cmt_created_at']     \n",
    "comment_df['cmt_created_at'] = comment_df['cmt_created_at'].apply(parse_date)\n",
    "model_df['pdf'] = model_df['pdf'].astype(float)\n",
    "model_df['cumulative_num'] = model_df['cumulative_num'].astype(int)\n",
    "model_df['post_type'] = model_df['post_type'].astype(int)\n",
    "model_df['post_type'] = model_df['post_type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering (only for test)\n",
    "cutoff_time = collected_at - datetime.timedelta(hours=12)\n",
    "post_df = post_df[post_df['created_at'] > cutoff_time]\n",
    "comment_df = comment_df[comment_df['cmt_created_at'] > cutoff_time]\n",
    "post_df = post_df[post_df['created_at'] <= collected_at] \n",
    "comment_df = comment_df[comment_df['cmt_created_at'] <= collected_at]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_comment_per_post_df = comment_df[['post_id', 'cmt_author']].groupby(['post_id']).agg({'cmt_author': 'count'}).rename(columns={'cmt_author': 'comments'})\n",
    "number_of_comment_per_post_df = number_of_comment_per_post_df.reset_index()\n",
    "number_of_comment_per_post_df.loc[number_of_comment_per_post_df['comments']>200] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/data_type_ops/datetime_ops.py:98: UserWarning: Note that there is a behavior difference of timestamp subtraction. The timestamp subtraction returns an integer in seconds, whereas pandas returns 'timedelta64[ns]'.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `apply`, it is expensive to infer the data type internally.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/generic.py:647: UserWarning: We recommend using `Series.to_numpy()` instead.\n",
      "  warnings.warn(\"We recommend using `{}.to_numpy()` instead.\".format(type(self).__name__))\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/generic.py:647: UserWarning: We recommend using `Series.to_numpy()` instead.\n",
      "  warnings.warn(\"We recommend using `{}.to_numpy()` instead.\".format(type(self).__name__))\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `apply`, it is expensive to infer the data type internally.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/generic.py:647: UserWarning: We recommend using `Series.to_numpy()` instead.\n",
      "  warnings.warn(\"We recommend using `{}.to_numpy()` instead.\".format(type(self).__name__))\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/generic.py:647: UserWarning: We recommend using `Series.to_numpy()` instead.\n",
      "  warnings.warn(\"We recommend using `{}.to_numpy()` instead.\".format(type(self).__name__))\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TIME_INTERVAL = 5 * 60\n",
    "post_df = ps.merge(post_df, number_of_comment_per_post_df, left_on='id', right_on='post_id', how='left')\n",
    "post_df = post_df.drop(columns=['id'])\n",
    "post_df['relatvie_time'] =  ((collected_at - post_df['created_at']) // TIME_INTERVAL) * 5\n",
    "post_df = predict_post_type(post_df, model_df)\n",
    "post_df['sns_id'] = 0 # TODO: use sns_id from input data. (to be deleted)\n",
    "post_df['collected_at'] = collected_at\n",
    "post_df['batch_id'] = int(collected_at.strftime('%Y%m%d%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "/Users/admin/Desktop/softeer-team-project/.final_check/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/pandas/namespace.py:1744: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n"
     ]
    }
   ],
   "source": [
    "post_df.to_csv(OUTPUT_FP, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_check",
   "language": "python",
   "name": "final_check"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
