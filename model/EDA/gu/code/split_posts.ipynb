{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events = [\"벤츠 화재\", \"아이오닉 누수\", \"아이오닉 iccu\", \"코나 화재\"]\n",
    "events = [\"코나 화재\"]\n",
    "communities = ['clien', 'bobae', 'fmkorea', 'naver_cafe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read All Posts with count of comments\n",
    "total_dfs = []\n",
    "for event in events:\n",
    "    per_community_dfs = []\n",
    "    for community in communities:\n",
    "        posts_df = pd.read_csv(f'{DATA_DIR}/{event}/{community}_posts.csv') \n",
    "        posts_df['from'] = community\n",
    "\n",
    "        comments_df = pd.read_csv(f'../data/{event}/{community}_comments.csv') \n",
    "        if community=='clien': #TODO: clien dataset cmt_author, post_id가 바뀌어 있음.\n",
    "            comments_df.columns = ['cmt_author', 'cmt_count', 'post_id', 'cmt_created_at']\n",
    "        comments_df = comments_df.groupby(['post_id'], as_index = False).agg({\n",
    "            'cmt_author': ['count'],\n",
    "        })\n",
    "\n",
    "        comments_df.columns = comments_df.columns.droplevel(0)\n",
    "        comments_df.columns = ['post_id', 'cmt_count']\n",
    "        per_community_df = pd.merge(posts_df, comments_df, left_on='id', right_on='post_id', how='left')\n",
    "        per_community_dfs.append(per_community_df)\n",
    "    per_event_df = pd.concat(per_community_dfs)\n",
    "    total_dfs.append(per_event_df)\n",
    "df = pd.concat(total_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df = df.dropna(subset=['created_at']) # 생성 시간이 없는 게시물 제거\n",
    "df.views = df.views.map(str).apply(remove_commna).apply(convert_str_to_int)\n",
    "df.likes = df.likes.map(str).apply(remove_commna).apply(convert_str_to_float)\n",
    "df.created_at = df.created_at.apply(parse_dates)\n",
    "df.cmt_count = df.cmt_count.fillna(0).map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset (Hot Posts / Cold Posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_5_percent_view: 10186     \n",
      "top_5_percent_number_of_comments: 56     \n",
      "top_5_percent_likes: 17\n"
     ]
    }
   ],
   "source": [
    "top_3_percent_view = get_target_val_by_percent(df, 'views', 0.97)\n",
    "top_3_percent_number_of_comments = get_target_val_by_percent(df, 'cmt_count', 0.97)\n",
    "top_3_percent_likes = get_target_val_by_percent(df, 'likes', 0.97)\n",
    "print(f\"top_5_percent_view: {top_3_percent_view} \\\n",
    "    \\ntop_5_percent_number_of_comments: {top_3_percent_number_of_comments} \\\n",
    "    \\ntop_5_percent_likes: {top_3_percent_likes}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = ((df.views >= top_3_percent_view) \\\n",
    "    | (df.cmt_count>=top_3_percent_number_of_comments) \\\n",
    "    # | (df.likes>=top_3_percent_likes) \\\n",
    "    )\n",
    "    \n",
    "df = df.drop(['post_id', 'cmt_count'], axis=1) # Only the information obtained from the posts is kept.\n",
    "\n",
    "hot_posts_df = df[condition]\n",
    "cold_posts_df = df[~condition]\n",
    "assert hot_posts_df.shape[0]+cold_posts_df.shape[0] == df.shape[0]\n",
    "\n",
    "os.makedirs(f\"{DATA_DIR}/splitted/\", exist_ok=True)           \n",
    "hot_posts_df.to_csv(f'{DATA_DIR}/splitted/hot_posts.csv', index=False)\n",
    "cold_posts_df.to_csv(f'{DATA_DIR}/splitted/cold_posts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_check",
   "language": "python",
   "name": "final_check"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
